#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI ê¸°ë°˜ ìœ ì‚¬ë„ ë§¤ì¹­ ëª¨ë“ˆ
Google Gemini APIë¥¼ í™œìš©í•œ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ë¶„ì„
"""

import google.generativeai as genai
import os
from typing import List, Dict, Tuple, Optional
import json
from functools import lru_cache
import time


class GeminiMatcher:
    """Gemini AIë¥¼ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­"""

    def __init__(self, api_key: Optional[str] = None):
        """
        Gemini Matcher ì´ˆê¸°í™”

        Args:
            api_key: Gemini API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ìŒ)
        """
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')

        if not self.api_key:
            raise ValueError(
                "Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                "GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_key íŒŒë¼ë¯¸í„°ë¥¼ ì „ë‹¬í•˜ì„¸ìš”."
            )

        # Gemini ì´ˆê¸°í™”
        genai.configure(api_key=self.api_key)
        # ìµœì‹  ì•ˆì • ëª¨ë¸ ì‚¬ìš©
        self.model = genai.GenerativeModel('gemini-2.5-flash')

        # ìºì‹œ (ê°™ì€ ìš”ì²­ ë°˜ë³µ ë°©ì§€)
        self.cache = {}

    @lru_cache(maxsize=1000)
    def calculate_semantic_similarity(
        self,
        text1: str,
        text2: str,
        context: str = "ì—‘ì…€ ì»¬ëŸ¼ëª…"
    ) -> Dict[str, any]:
        """
        AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê³„ì‚°

        Args:
            text1: ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸
            text2: ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸
            context: ì»¨í…ìŠ¤íŠ¸ (ì»¬ëŸ¼ëª…, ê°’ ë“±)

        Returns:
            {
                'similarity': 0-100 ì‚¬ì´ì˜ ìœ ì‚¬ë„ ì ìˆ˜,
                'is_similar': ìœ ì‚¬ ì—¬ë¶€ (bool),
                'reason': íŒë‹¨ ì´ìœ ,
                'mapping': ë§¤ì¹­ ì œì•ˆ
            }
        """
        # ìºì‹œ í™•ì¸
        cache_key = f"{text1}||{text2}||{context}"
        if cache_key in self.cache:
            return self.cache[cache_key]

        # Geminiì—ê²Œ ì§ˆë¬¸
        prompt = f"""
ë‹¹ì‹ ì€ ì—‘ì…€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‘ í…ìŠ¤íŠ¸ê°€ ê°™ì€ ì˜ë¯¸ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

**ì»¨í…ìŠ¤íŠ¸**: {context}

**í…ìŠ¤íŠ¸ 1**: "{text1}"
**í…ìŠ¤íŠ¸ 2**: "{text2}"

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”:
1. ë™ì¼í•œ ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ”ê°€? (ì˜ˆ: "ì´ë¦„"ê³¼ "ì„±ëª…", "í•™êµ"ì™€ "ëŒ€í•™êµ")
2. ìœ ì‚¬í•œ ê°œë…ì¸ê°€? (ì˜ˆ: "ì „ê³µ"ê³¼ "ì „ê³µë¶„ì•¼")
3. ë‹¤êµ­ì–´ í‘œí˜„ì¸ê°€? (ì˜ˆ: "name"ê³¼ "ì´ë¦„")
4. ì•½ì–´ì™€ ì „ì²´ í‘œí˜„ì¸ê°€? (ì˜ˆ: "HP"ì™€ "íœ´ëŒ€í°", "email"ê³¼ "ì´ë©”ì¼")
5. í•œìì™€ í•œê¸€ í‘œí˜„ì¸ê°€? (ì˜ˆ: "å¤§å­¸"ê³¼ "ëŒ€í•™")

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
    "similarity": 0-100 ì‚¬ì´ì˜ ìˆ«ì (100ì´ ì™„ì „ ë™ì¼),
    "is_similar": true ë˜ëŠ” false (ìœ ì‚¬ë„ 70 ì´ìƒì´ë©´ true),
    "reason": "íŒë‹¨ ì´ìœ ë¥¼ í•œêµ­ì–´ë¡œ ì„¤ëª…",
    "mapping": "í†µì¼ëœ í‘œí˜„ ì œì•ˆ"
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤.
"""

        try:
            response = self.model.generate_content(prompt)
            result_text = response.text.strip()

            # JSON íŒŒì‹±
            # Geminiê°€ ```json ``` ë¡œ ê°ìŒ€ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œê±°
            if result_text.startswith('```json'):
                result_text = result_text[7:]
            if result_text.endswith('```'):
                result_text = result_text[:-3]
            result_text = result_text.strip()

            result = json.loads(result_text)

            # ìºì‹œì— ì €ì¥
            self.cache[cache_key] = result

            return result

        except Exception as e:
            print(f"âš ï¸  AI ë¶„ì„ ì‹¤íŒ¨ ({text1} â†” {text2}): {str(e)}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                'similarity': 0,
                'is_similar': False,
                'reason': f'AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}',
                'mapping': text1
            }

    def match_columns_batch(
        self,
        columns_list: List[List[str]]
    ) -> Dict[str, List[str]]:
        """
        ì—¬ëŸ¬ íŒŒì¼ì˜ ì»¬ëŸ¼ë“¤ì„ ì¼ê´„ ë§¤ì¹­

        Args:
            columns_list: ê° íŒŒì¼ì˜ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë“¤

        Returns:
            {í†µí•©ì»¬ëŸ¼ëª…: [ì›ë³¸ì»¬ëŸ¼ëª…ë“¤]}
        """
        print("\nğŸ¤– AI ê¸°ë°˜ ì»¬ëŸ¼ ë§¤ì¹­ ì‹œì‘...")

        # ëª¨ë“  ê³ ìœ  ì»¬ëŸ¼ ìˆ˜ì§‘
        all_columns = []
        for columns in columns_list:
            all_columns.extend(columns)
        unique_columns = list(set(all_columns))

        # ì»¬ëŸ¼ ê·¸ë£¹í™”
        column_groups = {}
        processed = set()

        for i, col1 in enumerate(unique_columns):
            if col1 in processed:
                continue

            group = [col1]
            processed.add(col1)

            # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ë“¤ê³¼ ë¹„êµ
            for col2 in unique_columns[i+1:]:
                if col2 in processed:
                    continue

                # AIë¡œ ìœ ì‚¬ë„ ê³„ì‚°
                result = self.calculate_semantic_similarity(
                    col1, col2,
                    context="ì—‘ì…€ ì»¬ëŸ¼ëª… (í•™ìƒ/êµì‚¬ ì •ë³´)"
                )

                if result['is_similar']:
                    group.append(col2)
                    processed.add(col2)
                    print(f"  ğŸ”— ë§¤ì¹­: '{col1}' â†” '{col2}' (ìœ ì‚¬ë„: {result['similarity']}%, {result['reason']})")

                # API í˜¸ì¶œ ì œí•œ ëŒ€ë¹„
                time.sleep(0.1)

            # ëŒ€í‘œ ì»¬ëŸ¼ëª… ì„ íƒ (AI ì œì•ˆ ë˜ëŠ” ì²« ë²ˆì§¸)
            if len(group) > 1:
                # AIì—ê²Œ ìµœì ì˜ ì»¬ëŸ¼ëª… ì œì•ˆ ë°›ê¸°
                representative = self._select_best_column_name(group)
            else:
                representative = col1

            column_groups[representative] = group

        return column_groups

    def _select_best_column_name(self, column_names: List[str]) -> str:
        """
        ì—¬ëŸ¬ ì»¬ëŸ¼ëª… ì¤‘ ê°€ì¥ ì í•©í•œ ê²ƒì„ AIê°€ ì„ íƒ

        Args:
            column_names: ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸

        Returns:
            ì„ íƒëœ ì»¬ëŸ¼ëª…
        """
        if len(column_names) == 1:
            return column_names[0]

        prompt = f"""
ë‹¤ìŒ ì»¬ëŸ¼ëª…ë“¤ ì¤‘ ê°€ì¥ í‘œì¤€ì ì´ê³  ëª…í™•í•œ ê²ƒì„ í•˜ë‚˜ ì„ íƒí•˜ì„¸ìš”:

{', '.join([f'"{name}"' for name in column_names])}

ì„ íƒ ê¸°ì¤€:
1. ê°€ì¥ ëª…í™•í•˜ê³  í‘œì¤€ì ì¸ í‘œí˜„
2. í•œê¸€ > ì˜ì–´ (í•œêµ­ ë°ì´í„°ì´ë¯€ë¡œ)
3. ì „ì²´ í‘œí˜„ > ì•½ì–´
4. ì¼ë°˜ì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©ë˜ëŠ” í‘œí˜„

**ì‘ë‹µ í˜•ì‹**: ì„ íƒí•œ ì»¬ëŸ¼ëª…ë§Œ ì¶œë ¥ (ë”°ì˜´í‘œ ì—†ì´)
"""

        try:
            response = self.model.generate_content(prompt)
            selected = response.text.strip().strip('"\'')

            # ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸
            if selected in column_names:
                return selected
            else:
                # AI ì‘ë‹µì´ ì´ìƒí•˜ë©´ ì²« ë²ˆì§¸ ì„ íƒ
                return column_names[0]

        except Exception as e:
            print(f"âš ï¸  ì»¬ëŸ¼ëª… ì„ íƒ ì‹¤íŒ¨: {str(e)}")
            return column_names[0]

    def match_values_smart(
        self,
        values: List[str],
        value_type: str = "ì¼ë°˜"
    ) -> Dict[str, List[str]]:
        """
        ê°’ë“¤ì„ AIë¡œ ë¶„ì„í•˜ì—¬ ê·¸ë£¹í™”

        Args:
            values: ê°’ ë¦¬ìŠ¤íŠ¸
            value_type: ê°’ íƒ€ì… (í•™êµëª…, ì´ë¦„, ì£¼ì†Œ ë“±)

        Returns:
            {ëŒ€í‘œê°’: [ìœ ì‚¬í•œ ê°’ë“¤]}
        """
        unique_values = list(set([str(v) for v in values if v and str(v).strip()]))

        if len(unique_values) <= 1:
            return {unique_values[0]: unique_values} if unique_values else {}

        print(f"\nğŸ¤– AI ê¸°ë°˜ ê°’ ë§¤ì¹­ ì‹œì‘ (íƒ€ì…: {value_type})...")

        value_groups = {}
        processed = set()

        for i, val1 in enumerate(unique_values):
            if val1 in processed:
                continue

            group = [val1]
            processed.add(val1)

            for val2 in unique_values[i+1:]:
                if val2 in processed:
                    continue

                # AIë¡œ ìœ ì‚¬ë„ ê³„ì‚°
                result = self.calculate_semantic_similarity(
                    val1, val2,
                    context=f"{value_type} ê°’"
                )

                if result['is_similar']:
                    group.append(val2)
                    processed.add(val2)
                    print(f"  ğŸ”— ë§¤ì¹­: '{val1}' â†” '{val2}' (ìœ ì‚¬ë„: {result['similarity']}%)")

                time.sleep(0.1)

            # ëŒ€í‘œê°’: AIê°€ ì œì•ˆí•œ mapping ë˜ëŠ” ê°€ì¥ ê¸´ ê°’
            if len(group) > 1 and result.get('mapping'):
                representative = result['mapping']
            else:
                representative = max(group, key=len)

            value_groups[representative] = group

        return value_groups

    def verify_and_expand_school_name(
        self,
        school_name: str,
        gangwon_regions: Dict[str, str]
    ) -> Dict[str, str]:
        """
        AIë¥¼ ì‚¬ìš©í•˜ì—¬ í•™êµëª… ê²€ì¦ ë° í™•ì¥
        ì¤‘ê³ ë“±í•™êµì˜ ê²½ìš° í’€ë„¤ì„ í™•ì¸ í›„ ê°•ì›ë„ êµìœ¡ì²­ ìë™ ë§¤ì¹­

        Args:
            school_name: í•™êµëª… (ì•½ì¹­ ë˜ëŠ” í’€ë„¤ì„)
            gangwon_regions: ê°•ì›ë„ ì§€ì—­ëª…â†’êµìœ¡ì²­ëª… ë§¤í•‘ ë”•ì…”ë„ˆë¦¬

        Returns:
            {
                'full_name': í’€ë„¤ì„ í•™êµëª…,
                'education_office': êµìœ¡ì§€ì›ì²­ëª… (ê°•ì›ë„ ë‚´ í•™êµì¸ ê²½ìš°),
                'region': ì§€ì—­ëª…,
                'confidence': ì‹ ë¢°ë„ (0-100),
                'explanation': ì„¤ëª…
            }
        """
        if not school_name or not school_name.strip():
            return {
                'full_name': school_name,
                'education_office': '',
                'region': '',
                'confidence': 0,
                'explanation': 'ë¹ˆ í•™êµëª…'
            }

        cache_key = f"school_verify||{school_name}"
        if cache_key in self.cache:
            return self.cache[cache_key]

        # ê°•ì›ë„ ì§€ì—­ ëª©ë¡ ìƒì„±
        region_list = ', '.join(gangwon_regions.keys())

        prompt = f"""
ë‹¹ì‹ ì€ ê°•ì›ë„ êµìœ¡ì²­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™êµëª…ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.

**ì…ë ¥ í•™êµëª…**: "{school_name}"

**ê°•ì›ë„ ì§€ì—­ ëª©ë¡**: {region_list}

**ì‘ì—…**:
1. í•™êµëª…ì´ ì•½ì¹­ì¸ ê²½ìš° ì •ì‹ ëª…ì¹­ìœ¼ë¡œ í™•ì¥í•˜ì„¸ìš”
   ì˜ˆ: "ì¶˜ì²œê³µê³ " â†’ "ì¶˜ì²œê³µì—…ê³ ë“±í•™êµ"
       "ì›ì£¼ì—¬ê³ " â†’ "ì›ì£¼ì—¬ìê³ ë“±í•™êµ"
       "ê°•ë¦‰ê³ " â†’ "ê°•ë¦‰ê³ ë“±í•™êµ"
       "ì‚¼ì²™ì¤‘" â†’ "ì‚¼ì²™ì¤‘í•™êµ"

2. í•™êµê°€ ê°•ì›ë„ ë‚´ í•™êµì¸ì§€ í™•ì¸í•˜ê³ , í•´ë‹¹ ì§€ì—­ì„ ì°¾ìœ¼ì„¸ìš”
   ì˜ˆ: "ì¶˜ì²œê³µì—…ê³ ë“±í•™êµ" â†’ ì¶˜ì²œ
       "ì›ì£¼ì—¬ìê³ ë“±í•™êµ" â†’ ì›ì£¼
       "ê°•ë¦‰ì¤‘ì•™ì´ˆë“±í•™êµ" â†’ ê°•ë¦‰

3. ì‹ ë¢°ë„ë¥¼ ê³„ì‚°í•˜ì„¸ìš” (0-100)
   - ê°•ì›ë„ ë‚´ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í•™êµ: 90-100
   - ê°•ì›ë„ ë‚´ í•™êµë¡œ ì¶”ì •: 70-89
   - ê°•ì›ë„ ì™¸ ì§€ì—­ í•™êµ: 50-69
   - ë¶ˆëª…í™•: 0-49

**ì‘ë‹µ í˜•ì‹** (JSON):
{{
    "full_name": "ì •ì‹ í•™êµëª… (í™•ì¥ëœ í’€ë„¤ì„)",
    "region": "ì§€ì—­ëª… (ê°•ì›ë„ ì§€ì—­ ëª©ë¡ ì¤‘ í•˜ë‚˜, ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
    "confidence": 0-100 ì‚¬ì´ì˜ ìˆ«ì,
    "explanation": "íŒë‹¨ ê·¼ê±° ì„¤ëª…"
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

        try:
            response = self.model.generate_content(prompt)
            result_text = response.text.strip()

            # JSON íŒŒì‹±
            if result_text.startswith('```json'):
                result_text = result_text[7:]
            if result_text.endswith('```'):
                result_text = result_text[:-3]
            result_text = result_text.strip()

            result = json.loads(result_text)

            # êµìœ¡ì²­ëª… ì¶”ê°€
            region = result.get('region', '')
            education_office = ''
            if region and region in gangwon_regions:
                education_office = gangwon_regions[region]

            result['education_office'] = education_office

            # ìºì‹œì— ì €ì¥
            self.cache[cache_key] = result

            return result

        except Exception as e:
            print(f"âš ï¸  í•™êµëª… ê²€ì¦ ì‹¤íŒ¨ ({school_name}): {str(e)}")
            return {
                'full_name': school_name,
                'education_office': '',
                'region': '',
                'confidence': 0,
                'explanation': f'AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}'
            }


def test_gemini_matcher():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    import os

    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        return

    matcher = GeminiMatcher(api_key)

    # í…ŒìŠ¤íŠ¸ 1: ì»¬ëŸ¼ëª… ìœ ì‚¬ë„
    print("=" * 70)
    print("í…ŒìŠ¤íŠ¸ 1: ì»¬ëŸ¼ëª… ìœ ì‚¬ë„")
    print("=" * 70)

    test_pairs = [
        ("ì´ë¦„", "ì„±ëª…"),
        ("í•™êµ", "ëŒ€í•™êµ"),
        ("ì „ê³µ", "ì „ê³µë¶„ì•¼"),
        ("ì—°ë½ì²˜", "ì „í™”ë²ˆí˜¸"),
        ("email", "ì´ë©”ì¼"),
        ("HP", "íœ´ëŒ€í°"),
    ]

    for col1, col2 in test_pairs:
        result = matcher.calculate_semantic_similarity(col1, col2)
        print(f"\n'{col1}' â†” '{col2}'")
        print(f"  ìœ ì‚¬ë„: {result['similarity']}%")
        print(f"  ìœ ì‚¬í•¨: {result['is_similar']}")
        print(f"  ì´ìœ : {result['reason']}")
        print(f"  ì œì•ˆ: {result['mapping']}")


if __name__ == '__main__':
    test_gemini_matcher()
