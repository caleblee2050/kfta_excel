#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excel Unifier - ì›¹ ëŒ€ì‹œë³´ë“œ
KFTA í‘œì¤€ í˜•ì‹ ì „ìš© UI
"""

import io
import os
import tempfile
from datetime import datetime
from typing import Dict

import pandas as pd
import plotly.express as px
import streamlit as st

try:
    from .excel_unifier import ExcelUnifier
except ImportError:
    from excel_unifier import ExcelUnifier

try:
    from dotenv import load_dotenv
except ImportError:
    def load_dotenv() -> bool:
        return False


__version__ = "1.5.0"
__release_date__ = "2026-02-14"

st.set_page_config(
    page_title="KFTA Excel Unifier",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.markdown(
    """
<style>
@import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');

:root {
  --bg: #f4f6f8;
  --panel: #ffffff;
  --ink: #111827;
  --muted: #4b5563;
  --line: #d6dde4;
  --brand: #0f4c81;
  --brand-dark: #0b3a62;
}

html, body, [class*="css"]  {
  font-family: "Pretendard", "Noto Sans KR", "Segoe UI", sans-serif;
}

.stApp {
  background:
    radial-gradient(1000px 280px at 10% -10%, #e5edf7 0%, transparent 60%),
    radial-gradient(800px 240px at 90% -20%, #e9eef4 0%, transparent 62%),
    var(--bg);
}

.shell-title {
  font-size: 2rem;
  font-weight: 750;
  letter-spacing: -0.02em;
  color: var(--ink);
  margin-bottom: 0.25rem;
}

.shell-sub {
  font-size: 0.98rem;
  color: var(--muted);
  margin-bottom: 0.75rem;
}

.notice {
  border: 1px solid var(--line);
  background: var(--panel);
  border-radius: 12px;
  padding: 0.75rem 0.9rem;
  color: var(--muted);
  margin-bottom: 1rem;
}

.stButton button[kind="primary"] {
  background: linear-gradient(90deg, var(--brand), var(--brand-dark));
  border: 0;
  border-radius: 10px;
}

.stTabs [data-baseweb="tab-list"] {
  gap: 0.4rem;
}

.stTabs [data-baseweb="tab"] {
  border-radius: 8px;
}
</style>
""",
    unsafe_allow_html=True,
)


def _normalize_missing(value) -> bool:
    if pd.isna(value):
        return True
    text = str(value).strip().lower()
    return text in {"", "nan", "none", "null"}


def _quality_summary(df: pd.DataFrame) -> Dict[str, float]:
    if df is None or df.empty:
        return {"quality_score": 0.0, "missing_ratio": 100.0, "issue_rows": 0}

    key_candidates = ["ì´ë¦„", "í˜„ì¬êµìœ¡ì²­", "í˜„ì¬ë¶„íšŒ", "ë°œë ¹êµìœ¡ì²­", "ë°œë ¹ë¶„íšŒ", "ê³¼ëª©", "ì§ìœ„"]
    key_columns = [c for c in key_candidates if c in df.columns and (~df[c].map(_normalize_missing)).any()]
    if not key_columns:
        key_columns = list(df.columns[: min(len(df.columns), 5)])

    checks = df[key_columns].apply(lambda col: col.map(_normalize_missing))
    missing_ratio = float(checks.mean().mean() * 100)
    issue_threshold = max(2, (len(key_columns) + 1) // 2)
    issue_rows = int((checks.sum(axis=1) >= issue_threshold).sum())
    quality_score = max(0.0, min(100.0, 100.0 - missing_ratio))
    return {
        "quality_score": round(quality_score, 1),
        "missing_ratio": round(missing_ratio, 1),
        "issue_rows": issue_rows,
    }


def _issue_rows(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame()

    key_columns = [
        c for c in ["ì´ë¦„", "í˜„ì¬êµìœ¡ì²­", "í˜„ì¬ë¶„íšŒ", "ë°œë ¹êµìœ¡ì²­", "ë°œë ¹ë¶„íšŒ", "ê³¼ëª©", "ì§ìœ„"]
        if c in df.columns and (~df[c].map(_normalize_missing)).any()
    ]
    if not key_columns:
        return pd.DataFrame()

    checks = df[key_columns].apply(lambda col: col.map(_normalize_missing))
    issue_threshold = max(2, (len(key_columns) + 1) // 2)
    issue_mask = checks.sum(axis=1) >= issue_threshold
    issues = df.loc[issue_mask, key_columns].copy()
    issues.insert(0, "ë¹ˆí•µì‹¬í•„ë“œìˆ˜", checks.loc[issue_mask].sum(axis=1))
    return issues.sort_values("ë¹ˆí•µì‹¬í•„ë“œìˆ˜", ascending=False)


def _init_state() -> None:
    if "unifier" not in st.session_state:
        st.session_state.unifier = None
    if "unified_df" not in st.session_state:
        st.session_state.unified_df = None
    if "uploaded_files_data" not in st.session_state:
        st.session_state.uploaded_files_data = []
    if "quality" not in st.session_state:
        st.session_state.quality = None


def _sidebar_controls():
    with st.sidebar:
        st.header("ì²˜ë¦¬ ì„¤ì •")

        load_dotenv()
        api_key = os.getenv("GEMINI_API_KEY")
        gemini_model_default = os.getenv("GEMINI_MODEL", "gemini-3-flash")

        st.caption("ì¶œë ¥ í˜•ì‹: KFTA í‘œì¤€ìœ¼ë¡œ ê³ ì •")

        use_ai = st.checkbox(
            "AI ë§¤ì¹­ ì‚¬ìš©",
            value=bool(api_key),
            help="ì˜ë¯¸ ê¸°ë°˜ ë§¤ì¹­(ë™ì˜ì–´/ì•½ì–´/ì˜ë¬¸)ì„ í™œì„±í™”í•©ë‹ˆë‹¤.",
        )
        gemini_model = gemini_model_default

        if use_ai:
            if api_key:
                st.success("GEMINI_API_KEY í™•ì¸ë¨")
            else:
                st.warning("GEMINI_API_KEY ë¯¸ì„¤ì • ìƒíƒœì…ë‹ˆë‹¤. AI ìš”ì²­ì´ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ë§¤ì¹­ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            gemini_model = st.text_input("Gemini ëª¨ë¸", value=gemini_model_default)

        threshold = st.slider("ìœ ì‚¬ë„ ì„ê³„ê°’", min_value=0, max_value=100, value=85)

        dedup_keys_raw = st.text_input(
            "ì¤‘ë³µ ì œê±° í‚¤ ì»¬ëŸ¼",
            value="ì´ë¦„ í˜„ì¬ë¶„íšŒ",
            help="ê³µë°±ìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”. ì˜ˆ) ì´ë¦„ í˜„ì¬ë¶„íšŒ",
        )
        dedup_keys = [key.strip() for key in dedup_keys_raw.split() if key.strip()]

        drop_issue_rows = st.checkbox(
            "í•µì‹¬ í•„ë“œ ê³µë€ í–‰ ì œê±°",
            value=True,
            help="í•µì‹¬ í•„ë“œê°€ ëŒ€ë¶€ë¶„ ë¹„ì–´ ìˆëŠ” í–‰ì„ ê²°ê³¼ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.",
        )

        st.divider()
        st.caption(f"Version {__version__} ({__release_date__})")
        st.caption("KFTA ì „ìš© í†µí•© ì›Œí¬í”Œë¡œìš°")

        return use_ai, gemini_model, threshold, dedup_keys, drop_issue_rows


def _render_header() -> None:
    st.markdown('<div class="shell-title">ê°•ì›êµì´ ì—‘ì…€ í†µí•©</div>', unsafe_allow_html=True)
    st.markdown(
        '<div class="shell-sub">ë³µìˆ˜ íŒŒì¼ì„ KFTA í‘œì¤€ìœ¼ë¡œ í†µí•©í•˜ê³  í’ˆì§ˆì„ ë°”ë¡œ í™•ì¸í•©ë‹ˆë‹¤.</div>',
        unsafe_allow_html=True,
    )
    st.markdown(
        '<div class="notice">1) íŒŒì¼ ì—…ë¡œë“œ â†’ 2) í†µí•© ì‹¤í–‰ â†’ 3) í’ˆì§ˆ ê²€í†  â†’ 4) ì—‘ì…€ ë‹¤ìš´ë¡œë“œ</div>',
        unsafe_allow_html=True,
    )


def _save_uploaded_files(uploaded_files):
    file_info = []
    st.session_state.uploaded_files_data = []

    for file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.name)[1]) as tmp:
            tmp.write(file.getvalue())
            tmp_path = tmp.name

        st.session_state.uploaded_files_data.append(
            {"name": file.name, "path": tmp_path, "size": file.size}
        )

        try:
            if file.name.endswith(".csv"):
                df = pd.read_csv(tmp_path)
                file_info.append(
                    {
                        "íŒŒì¼ëª…": file.name,
                        "ì‹œíŠ¸": "-",
                        "í–‰ ìˆ˜": len(df),
                        "ì»¬ëŸ¼ ìˆ˜": len(df.columns),
                        "í¬ê¸°": f"{file.size / 1024:.1f} KB",
                    }
                )
            else:
                excel_file = pd.ExcelFile(tmp_path)
                for sheet_name in excel_file.sheet_names:
                    df = pd.read_excel(tmp_path, sheet_name=sheet_name)
                    if df.empty or len(df.columns) == 0:
                        continue
                    file_info.append(
                        {
                            "íŒŒì¼ëª…": file.name,
                            "ì‹œíŠ¸": sheet_name,
                            "í–‰ ìˆ˜": len(df),
                            "ì»¬ëŸ¼ ìˆ˜": len(df.columns),
                            "í¬ê¸°": f"{file.size / 1024:.1f} KB",
                        }
                    )
        except Exception as error:
            st.error(f"{file.name} ì½ê¸° ì‹¤íŒ¨: {error}")

    if file_info:
        st.dataframe(pd.DataFrame(file_info), use_container_width=True)


def main():
    _init_state()
    _render_header()
    use_ai, gemini_model, threshold, dedup_keys, drop_issue_rows = _sidebar_controls()

    tab1, tab2, tab3 = st.tabs(["íŒŒì¼ ì—…ë¡œë“œ", "í†µí•© ì‹¤í–‰", "ê²°ê³¼/í’ˆì§ˆ"])

    with tab1:
        uploaded_files = st.file_uploader(
            "ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (.xlsx, .xls, .csv)",
            type=["xlsx", "xls", "csv"],
            accept_multiple_files=True,
        )
        if uploaded_files:
            st.success(f"{len(uploaded_files)}ê°œ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
            _save_uploaded_files(uploaded_files)

    with tab2:
        if not st.session_state.uploaded_files_data:
            st.info("ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            st.write(f"{len(st.session_state.uploaded_files_data)}ê°œ íŒŒì¼ ì¤€ë¹„ë¨")
            if st.button("í†µí•© ì‹¤í–‰", type="primary", use_container_width=True):
                with st.spinner("í†µí•© ì²˜ë¦¬ ì¤‘..."):
                    try:
                        unifier = ExcelUnifier(
                            similarity_threshold=threshold,
                            use_ai=use_ai,
                            gemini_model=gemini_model,
                        )
                        file_paths = [f["path"] for f in st.session_state.uploaded_files_data]

                        progress = st.progress(0)
                        progress.progress(20)
                        unifier.load_excel_files(file_paths)

                        progress.progress(45)
                        column_mappings = unifier.analyze_columns()

                        progress.progress(75)
                        unified_df = unifier.unify_dataframes(
                            key_columns=dedup_keys or None,
                            output_format="kfta",
                        )

                        if drop_issue_rows and not unified_df.empty:
                            core_cols = [c for c in ["ì´ë¦„", "í˜„ì¬ë¶„íšŒ", "ë°œë ¹ë¶„íšŒ", "ê³¼ëª©", "ì§ìœ„"] if c in unified_df.columns]
                            if core_cols:
                                mask_has_value = unified_df[core_cols].apply(
                                    lambda row: any(not _normalize_missing(v) for v in row),
                                    axis=1,
                                )
                                unified_df = unified_df[mask_has_value].reset_index(drop=True)

                        progress.progress(100)

                        st.session_state.unifier = unifier
                        st.session_state.unified_df = unified_df
                        st.session_state.quality = _quality_summary(unified_df)

                        st.success("KFTA í†µí•©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

                        m1, m2, m3 = st.columns(3)
                        with m1:
                            st.metric("ì²˜ë¦¬ëœ íŒŒì¼", len(file_paths))
                        with m2:
                            original_count = sum(len(info["data"]) for info in unifier.dataframes)
                            st.metric("ì›ë³¸ í–‰ ìˆ˜", original_count)
                        with m3:
                            st.metric("í†µí•© í›„ í–‰ ìˆ˜", len(unified_df))

                        with st.expander("ì»¬ëŸ¼ ë§¤í•‘ ë³´ê¸°"):
                            mapping_data = []
                            for unified_col, original_cols in column_mappings.items():
                                if len(original_cols) > 1:
                                    mapping_data.append(
                                        {"í†µí•© ì»¬ëŸ¼": unified_col, "ì›ë³¸ ì»¬ëŸ¼ë“¤": ", ".join(original_cols)}
                                    )
                            if mapping_data:
                                st.dataframe(pd.DataFrame(mapping_data), use_container_width=True)

                    except Exception as error:
                        st.error(f"í†µí•© ì‹¤íŒ¨: {error}")

    with tab3:
        df = st.session_state.unified_df
        if df is None:
            st.info("í†µí•© ì‹¤í–‰ í›„ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            return

        quality = st.session_state.quality or _quality_summary(df)
        q1, q2, q3 = st.columns(3)
        with q1:
            st.metric("í’ˆì§ˆ ì ìˆ˜", f"{quality['quality_score']} / 100")
        with q2:
            st.metric("í•µì‹¬ í•„ë“œ ê²°ì¸¡ë¥ ", f"{quality['missing_ratio']}%")
        with q3:
            st.metric("ë¬¸ì œ ê°€ëŠ¥ í–‰", quality["issue_rows"])

        st.divider()
        show_rows = st.slider("ë¯¸ë¦¬ë³´ê¸° í–‰ ìˆ˜", 5, 200, 20)
        st.dataframe(df.head(show_rows), use_container_width=True)

        issues = _issue_rows(df)
        with st.expander("í’ˆì§ˆ ì´ìŠˆ ìƒì„¸", expanded=False):
            if issues.empty:
                st.success("í•µì‹¬ í•„ë“œ ê³µë€ì´ ë§ì€ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.warning(f"í•µì‹¬ í•„ë“œ ê²°ì¸¡ì´ ë§ì€ í–‰ {len(issues)}ê±´")
                st.dataframe(issues.head(200), use_container_width=True)

        st.divider()
        missing_data = pd.DataFrame(
            {
                "ì»¬ëŸ¼": df.columns,
                "ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)": (df.isnull().sum().values / max(1, len(df)) * 100).round(2),
            }
        ).sort_values("ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)", ascending=False)
        fig = px.bar(
            missing_data,
            x="ì»¬ëŸ¼",
            y="ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)",
            color="ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)",
            color_continuous_scale="Blues",
            title="ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ë¹„ìœ¨",
        )
        st.plotly_chart(fig, use_container_width=True)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="KFTA_í†µí•©ê²°ê³¼")
        output.seek(0)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.download_button(
            label="KFTA Excel ë‹¤ìš´ë¡œë“œ",
            data=output,
            file_name=f"kfta_unified_{timestamp}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )


if __name__ == "__main__":
    main()
